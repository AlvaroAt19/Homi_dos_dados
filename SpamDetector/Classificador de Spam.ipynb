{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00825f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994ca45",
   "metadata": {},
   "source": [
    "# Abrindo e entendendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a1e733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "ham\tU dun say so early hor... U c already then say...\n",
      "\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "\n",
      "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "\n",
      "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n',\n",
       " 'ham\\tOk lar... Joking wif u oni...\\n',\n",
       " \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\n\",\n",
       " 'ham\\tU dun say so early hor... U c already then say...\\n',\n",
       " \"ham\\tNah I don't think he goes to usf, he lives around here though\\n\",\n",
       " \"spam\\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\\n\",\n",
       " 'ham\\tEven my brother is not like to speak with me. They treat me like aids patent.\\n',\n",
       " \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\\n\",\n",
       " 'spam\\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\\n',\n",
       " 'spam\\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('SMSSpamCollection') as file:\n",
    "    tenlines = file.readlines()[:10]\n",
    "    for line in tenlines:\n",
    "        print(line)\n",
    "tenlines    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf64245",
   "metadata": {},
   "source": [
    "Temos um arquivo onde cada linha é uma mensagen com sua classificação em ham ou spam, separados por uma tabulação '\\t'. Logo podemos transformar isso em um dataset com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7700e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection', sep='\\t', names = ['class', 'msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d936bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10df71d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        msg                                                               \n",
       "      count unique                                                top freq\n",
       "class                                                                     \n",
       "ham    4825   4516                             Sorry, I'll call later   30\n",
       "spam    747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a2b85",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0312f52",
   "metadata": {},
   "source": [
    "Vamos tratar os dados, removendo mensagens repetidas, as pontuações e palavras que não agregam na análise conhecidas como stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48574ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True) #Removendo Duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8f4ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4516</td>\n",
       "      <td>4516</td>\n",
       "      <td>Black shirt n blue jeans... I thk i c ü...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "      <td>Hard LIVE 121 chat just 60p/min. Choose your g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        msg                                                               \n",
       "      count unique                                                top freq\n",
       "class                                                                     \n",
       "ham    4516   4516         Black shirt n blue jeans... I thk i c ü...    1\n",
       "spam    653    653  Hard LIVE 121 chat just 60p/min. Choose your g...    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ac2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removedor(mensagem):\n",
    "    '''Remove pontuação e stopwords de uma mensagem'''\n",
    "    for i in string.punctuation:#Removendo pontuação\n",
    "        if i in mensagem:\n",
    "            mensagem = mensagem.replace(i,'')\n",
    "    \n",
    "    stop_removed = []\n",
    "    for i in mensagem.split(): #Removendo stopwords\n",
    "        if i.lower() not in stopwords.words('english'):\n",
    "            stop_removed.append(i.lower())\n",
    "    \n",
    "    return ' '.join(stop_removed) #Retorna o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a18bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['msg'] = data['msg'].apply(removedor) #Aplicando o removedor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398a206",
   "metadata": {},
   "source": [
    "# Preparação para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a0a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_unig = CountVectorizer().fit(data['msg']) #Unigramas\n",
    "msg_unig = spm_unig.transform(data['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea6aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_bi = CountVectorizer(ngram_range=(2, 2)).fit(data['msg']) #Bigramas\n",
    "msg_bi = spm_bi.transform(data['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc3ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_tfidf = TfidfTransformer(norm=\"l1\").fit(msg_unig)#tfidf com unigramas\n",
    "msg_tfidf = spm_tfidf.transform(msg_unig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee566ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5169, 9437) (5169, 32056) (5169, 9437)\n"
     ]
    }
   ],
   "source": [
    "print(msg_unig.shape,msg_bi.shape, msg_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e483ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data['class'])\n",
    "print(y) # 0 para ham e 1 para spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900feea7",
   "metadata": {},
   "source": [
    "Criadas as matrizes esparsas vamos ao modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5995f",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57cf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unig, X_test_unig, y_train_unig, y_test_unig = train_test_split(msg_unig, y, test_size=0.3, random_state=19)\n",
    "X_train_bi, X_test_bi, y_train_bi, y_test_bi= train_test_split(msg_bi, y,  test_size=0.3, random_state=19)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(msg_tfidf, y, test_size=0.3, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94179ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_log_reg = LogisticRegression().fit(X_train_unig,y_train_unig)\n",
    "bi_log_reg = LogisticRegression().fit(X_train_bi,y_train_bi)\n",
    "tfidf_log_reg = LogisticRegression().fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86df9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_log_pred = unig_log_reg.predict(X_test_unig)\n",
    "bi_log_pred = bi_log_reg.predict(X_test_bi)\n",
    "tfidf_log_pred = tfidf_log_reg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b73a35f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão logística para unigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1333\n",
      "        spam       0.98      0.80      0.88       218\n",
      "\n",
      "    accuracy                           0.97      1551\n",
      "   macro avg       0.98      0.90      0.93      1551\n",
      "weighted avg       0.97      0.97      0.97      1551\n",
      "\n",
      "\n",
      "Regressão logística para bigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      1.00      0.96      1333\n",
      "        spam       1.00      0.44      0.61       218\n",
      "\n",
      "    accuracy                           0.92      1551\n",
      "   macro avg       0.96      0.72      0.78      1551\n",
      "weighted avg       0.93      0.92      0.91      1551\n",
      "\n",
      "\n",
      "Regressão logística para tfidf:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      1.00      0.92      1333\n",
      "        spam       0.00      0.00      0.00       218\n",
      "\n",
      "    accuracy                           0.86      1551\n",
      "   macro avg       0.43      0.50      0.46      1551\n",
      "weighted avg       0.74      0.86      0.79      1551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Regressão logística para unigramas:\\n')\n",
    "print(classification_report(y_test_unig, unig_log_pred, target_names = ['ham','spam']))\n",
    "print('\\nRegressão logística para bigramas:\\n')\n",
    "print(classification_report(y_test_bi, bi_log_pred, target_names = ['ham','spam']))\n",
    "print('\\nRegressão logística para tfidf:\\n')\n",
    "print(classification_report(y_test_tfidf, tfidf_log_pred, target_names = ['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3e6c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_forest = RandomForestClassifier().fit(X_train_unig,y_train_unig)\n",
    "bi_forest = RandomForestClassifier().fit(X_train_bi,y_train_bi)\n",
    "tfidf_forest = RandomForestClassifier().fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f54e3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_forest_pred = unig_forest.predict(X_test_unig)\n",
    "bi_forest_pred = bi_forest.predict(X_test_bi)\n",
    "tfidf_forest_pred = tfidf_forest.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2db1d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest para unigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1333\n",
      "        spam       1.00      0.75      0.86       218\n",
      "\n",
      "    accuracy                           0.97      1551\n",
      "   macro avg       0.98      0.88      0.92      1551\n",
      "weighted avg       0.97      0.97      0.96      1551\n",
      "\n",
      "\n",
      "Random Forest para bigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      1.00      0.96      1333\n",
      "        spam       1.00      0.52      0.68       218\n",
      "\n",
      "    accuracy                           0.93      1551\n",
      "   macro avg       0.96      0.76      0.82      1551\n",
      "weighted avg       0.94      0.93      0.92      1551\n",
      "\n",
      "\n",
      "Random Forest para tfidf:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1333\n",
      "        spam       1.00      0.76      0.86       218\n",
      "\n",
      "    accuracy                           0.97      1551\n",
      "   macro avg       0.98      0.88      0.92      1551\n",
      "weighted avg       0.97      0.97      0.96      1551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest para unigramas:\\n')\n",
    "print(classification_report(y_test_unig, unig_forest_pred, target_names = ['ham','spam']))\n",
    "print('\\nRandom Forest para bigramas:\\n')\n",
    "print(classification_report(y_test_bi, bi_forest_pred, target_names = ['ham','spam']))\n",
    "print('\\nRandom Forest para tfidf:\\n')\n",
    "print(classification_report(y_test_tfidf, tfidf_forest_pred, target_names = ['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f0ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_nb = MultinomialNB().fit(X_train_unig,y_train_unig)\n",
    "bi_nb= MultinomialNB().fit(X_train_bi,y_train_bi)\n",
    "tfidf_nb = MultinomialNB().fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bbcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "unig_nb_pred = unig_nb.predict(X_test_unig)\n",
    "bi_nb_pred = bi_nb.predict(X_test_bi)\n",
    "tfidf_nb_pred = tfidf_nb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6abd3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes para unigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.99      1333\n",
      "        spam       0.90      0.94      0.92       218\n",
      "\n",
      "    accuracy                           0.98      1551\n",
      "   macro avg       0.94      0.96      0.95      1551\n",
      "weighted avg       0.98      0.98      0.98      1551\n",
      "\n",
      "\n",
      "Naive Bayes para bigramas:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.81      0.89      1333\n",
      "        spam       0.45      0.96      0.61       218\n",
      "\n",
      "    accuracy                           0.83      1551\n",
      "   macro avg       0.72      0.88      0.75      1551\n",
      "weighted avg       0.92      0.83      0.85      1551\n",
      "\n",
      "\n",
      "Naive Bayes para tfidf:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      1.00      0.92      1333\n",
      "        spam       0.00      0.00      0.00       218\n",
      "\n",
      "    accuracy                           0.86      1551\n",
      "   macro avg       0.43      0.50      0.46      1551\n",
      "weighted avg       0.74      0.86      0.79      1551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes para unigramas:\\n')\n",
    "print(classification_report(y_test_unig, unig_nb_pred, target_names = ['ham','spam']))\n",
    "print('\\nNaive Bayes para bigramas:\\n')\n",
    "print(classification_report(y_test_bi, bi_nb_pred, target_names = ['ham','spam']))\n",
    "print('\\nNaive Bayes para tfidf:\\n')\n",
    "print(classification_report(y_test_tfidf, tfidf_nb_pred, target_names = ['ham','spam'], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2145123",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c8cf1",
   "metadata": {},
   "source": [
    "Todos os modelos tiveram uma boa performance quando utilizado a matriz de unigramas\n",
    "\n",
    "o Random Forest conseguiu performar bem em todos os testes, já os outros modelos só perfomaram bem com unigramas, no entanto a performance com unigramas do Naive Bayes foi a melhor de todas, com uma acurácia de 98%, e 99% de acerto para mensagens do tipo ham que são a maioria esmagadora do conjunto.\n",
    "\n",
    "Apesar de ter uma grande diferença de números entre ham e spam, conseguimos modelos não enviesados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
